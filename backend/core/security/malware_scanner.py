"""
Enhanced Malware Scanner for File Uploads
Task 1.2.3 Implementation - Advanced malware detection with behavioral analysis and real-time threat detection
"""

import os
import re
import hashlib
import logging
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict, deque
from django.core.exceptions import ValidationError
from django.conf import settings
from django.utils import timezone
from django.core.cache import cache

# Security logger
security_logger = logging.getLogger('security')

class BehavioralAnalyzer:
    """
    Behavioral analysis engine for detecting suspicious upload patterns
    Task 1.2.3 Implementation - Behavioral analysis component
    """
    
    def __init__(self):
        self.upload_patterns = defaultdict(list)
        self.suspicious_ips = set()
        self.threat_indicators = defaultdict(int)
        
    def analyze_upload_behavior(self, file_obj, client_ip: str, user_id: str = None) -> Dict[str, any]:
        """
        Analyze upload behavior for suspicious patterns
        
        Args:
            file_obj: Uploaded file object
            client_ip: Client IP address
            user_id: User ID if authenticated
            
        Returns:
            Behavioral analysis results
        """
        analysis_result = {
            'risk_score': 0,
            'behavioral_flags': [],
            'upload_velocity': 0,
            'pattern_anomalies': [],
            'ip_reputation': 'clean'
        }
        
        current_time = timezone.now()
        
        # Track upload patterns
        upload_key = f"upload_pattern:{client_ip}"
        recent_uploads = cache.get(upload_key, [])
        
        # Add current upload
        upload_info = {
            'timestamp': current_time.isoformat(),
            'filename': file_obj.name,
            'size': file_obj.size,
            'user_id': user_id
        }
        recent_uploads.append(upload_info)
        
        # Keep only last 24 hours
        cutoff_time = current_time - timedelta(hours=24)
        recent_uploads = [
            upload for upload in recent_uploads 
            if datetime.fromisoformat(upload['timestamp'].replace('Z', '+00:00')) > cutoff_time
        ]
        
        # Cache updated list
        cache.set(upload_key, recent_uploads, 86400)  # 24 hours
        
        # Analyze patterns
        analysis_result.update(self._analyze_upload_velocity(recent_uploads, analysis_result))
        analysis_result.update(self._analyze_file_patterns(recent_uploads, analysis_result))
        analysis_result.update(self._analyze_ip_reputation(client_ip, analysis_result))
        analysis_result.update(self._analyze_size_patterns(recent_uploads, analysis_result))
        analysis_result.update(self._analyze_timing_patterns(recent_uploads, analysis_result))
        
        # Calculate overall risk score
        analysis_result['risk_score'] = self._calculate_behavioral_risk_score(analysis_result)
        
        return analysis_result
    
    def _analyze_upload_velocity(self, uploads: List[Dict], result: Dict) -> Dict:
        """Analyze upload velocity for suspicious activity"""
        if len(uploads) < 2:
            return {}
        
        # Calculate uploads per hour
        time_span_hours = 24
        uploads_per_hour = len(uploads) / time_span_hours
        result['upload_velocity'] = uploads_per_hour
        
        # Flag high velocity
        if uploads_per_hour > 50:  # More than 50 uploads per hour
            result['behavioral_flags'].append('high_upload_velocity')
            result['risk_score'] += 30
        elif uploads_per_hour > 20:
            result['behavioral_flags'].append('elevated_upload_velocity')
            result['risk_score'] += 15
        
        # Check for burst uploads (many uploads in short time)
        recent_hour_uploads = [
            u for u in uploads 
            if datetime.fromisoformat(u['timestamp'].replace('Z', '+00:00')) > 
               timezone.now() - timedelta(hours=1)
        ]
        
        if len(recent_hour_uploads) > 20:
            result['behavioral_flags'].append('upload_burst')
            result['risk_score'] += 25
        
        return {}
    
    def _analyze_file_patterns(self, uploads: List[Dict], result: Dict) -> Dict:
        """Analyze file naming and type patterns"""
        if not uploads:
            return {}
        
        filenames = [upload['filename'] for upload in uploads]
        
        # Check for suspicious naming patterns
        suspicious_patterns = [
            r'^[a-f0-9]{32}\.',  # MD5-like names
            r'^[a-f0-9]{40}\.',  # SHA1-like names
            r'^temp_\d+\.',      # Temporary file names
            r'^test\d*\.',       # Test file names
            r'^\d+\.',           # Numeric names
            r'^[a-z]{1,3}\.',    # Very short names
        ]
        
        suspicious_count = 0
        for filename in filenames:
            for pattern in suspicious_patterns:
                if re.match(pattern, filename.lower()):
                    suspicious_count += 1
                    break
        
        if suspicious_count > len(filenames) * 0.7:  # More than 70% suspicious names
            result['behavioral_flags'].append('suspicious_naming_pattern')
            result['risk_score'] += 20
        
        # Check for identical filenames (potential automated uploads)
        filename_counts = defaultdict(int)
        for filename in filenames:
            filename_counts[filename] += 1
        
        max_duplicates = max(filename_counts.values()) if filename_counts else 0
        if max_duplicates > 5:
            result['behavioral_flags'].append('duplicate_filenames')
            result['risk_score'] += 15
        
        # Check for extension variations of same base name
        base_names = defaultdict(list)
        for filename in filenames:
            base_name = os.path.splitext(filename)[0]
            extension = os.path.splitext(filename)[1]
            base_names[base_name].append(extension)
        
        for base_name, extensions in base_names.items():
            if len(set(extensions)) > 3:  # Same base name with many extensions
                result['behavioral_flags'].append('extension_variation_attack')
                result['risk_score'] += 25
        
        return {}
    
    def _analyze_ip_reputation(self, client_ip: str, result: Dict) -> Dict:
        """Analyze IP reputation and history"""
        # Check if IP has been flagged before
        ip_flags_key = f"ip_flags:{client_ip}"
        ip_flags = cache.get(ip_flags_key, [])
        
        if ip_flags:
            result['ip_reputation'] = 'suspicious'
            result['behavioral_flags'].append('known_suspicious_ip')
            result['risk_score'] += 40
        
        # Check for rapid IP changes (if user is authenticated)
        # This would require session tracking - simplified for now
        
        return {}
    
    def _analyze_size_patterns(self, uploads: List[Dict], result: Dict) -> Dict:
        """Analyze file size patterns"""
        if len(uploads) < 3:
            return {}
        
        sizes = [upload['size'] for upload in uploads]
        
        # Check for identical sizes (potential automated uploads)
        size_counts = defaultdict(int)
        for size in sizes:
            size_counts[size] += 1
        
        max_identical_sizes = max(size_counts.values())
        if max_identical_sizes > len(sizes) * 0.8:  # More than 80% identical sizes
            result['behavioral_flags'].append('identical_file_sizes')
            result['risk_score'] += 20
        
        # Check for suspiciously small files
        small_files = [size for size in sizes if size < 100]  # Less than 100 bytes
        if len(small_files) > len(sizes) * 0.5:  # More than 50% very small files
            result['behavioral_flags'].append('many_tiny_files')
            result['risk_score'] += 15
        
        # Check for suspiciously large files
        large_files = [size for size in sizes if size > 50 * 1024 * 1024]  # More than 50MB
        if len(large_files) > 3:
            result['behavioral_flags'].append('many_large_files')
            result['risk_score'] += 10
        
        return {}
    
    def _analyze_timing_patterns(self, uploads: List[Dict], result: Dict) -> Dict:
        """Analyze upload timing patterns"""
        if len(uploads) < 3:
            return {}
        
        timestamps = [
            datetime.fromisoformat(upload['timestamp'].replace('Z', '+00:00'))
            for upload in uploads
        ]
        timestamps.sort()
        
        # Calculate intervals between uploads
        intervals = []
        for i in range(1, len(timestamps)):
            interval = (timestamps[i] - timestamps[i-1]).total_seconds()
            intervals.append(interval)
        
        if intervals:
            # Check for very regular intervals (potential bot behavior)
            avg_interval = sum(intervals) / len(intervals)
            regular_intervals = [
                interval for interval in intervals 
                if abs(interval - avg_interval) < avg_interval * 0.1  # Within 10% of average
            ]
            
            if len(regular_intervals) > len(intervals) * 0.8:  # More than 80% regular
                result['behavioral_flags'].append('regular_upload_intervals')
                result['risk_score'] += 25
            
            # Check for very rapid uploads
            rapid_uploads = [interval for interval in intervals if interval < 5]  # Less than 5 seconds
            if len(rapid_uploads) > len(intervals) * 0.5:  # More than 50% rapid
                result['behavioral_flags'].append('rapid_fire_uploads')
                result['risk_score'] += 30
        
        return {}
    
    def _calculate_behavioral_risk_score(self, analysis: Dict) -> int:
        """Calculate overall behavioral risk score"""
        base_score = analysis.get('risk_score', 0)
        
        # Adjust based on number of flags
        flag_count = len(analysis.get('behavioral_flags', []))
        if flag_count > 5:
            base_score += 20
        elif flag_count > 3:
            base_score += 10
        
        # Cap at 100
        return min(base_score, 100)
    
    def flag_suspicious_ip(self, client_ip: str, reason: str):
        """Flag an IP as suspicious"""
        ip_flags_key = f"ip_flags:{client_ip}"
        flags = cache.get(ip_flags_key, [])
        flags.append({
            'reason': reason,
            'timestamp': timezone.now().isoformat(),
        })
        cache.set(ip_flags_key, flags, 86400 * 7)  # Keep for 7 days
        
        security_logger.warning(f"IP flagged as suspicious: {client_ip} - {reason}")


class RealTimeThreatDetector:
    """
    Real-time threat detection system
    Task 1.2.3 Implementation - Real-time threat detection component
    """
    
    def __init__(self):
        self.threat_feeds = []
        self.active_threats = set()
        self.threat_cache_ttl = 3600  # 1 hour
        
    def check_real_time_threats(self, file_obj, file_hash: str) -> Dict[str, any]:
        """
        Check file against real-time threat intelligence
        
        Args:
            file_obj: File object
            file_hash: File hash
            
        Returns:
            Real-time threat analysis results
        """
        threat_result = {
            'threat_detected': False,
            'threat_sources': [],
            'threat_confidence': 0,
            'threat_details': []
        }
        
        # Check against cached threat intelligence
        threat_result.update(self._check_threat_intelligence(file_hash))
        
        # Check against dynamic analysis results
        threat_result.update(self._check_dynamic_analysis(file_obj))
        
        # Check against community reports
        threat_result.update(self._check_community_reports(file_hash))
        
        return threat_result
    
    def _check_threat_intelligence(self, file_hash: str) -> Dict:
        """Check against threat intelligence feeds"""
        # Check cached threat intelligence
        threat_key = f"threat_intel:{file_hash}"
        cached_threat = cache.get(threat_key)
        
        if cached_threat:
            return {
                'threat_detected': True,
                'threat_sources': ['threat_intelligence'],
                'threat_confidence': cached_threat.get('confidence', 80),
                'threat_details': [cached_threat.get('description', 'Known malicious file')]
            }
        
        # In a real implementation, this would query external threat feeds
        # For now, we'll simulate with a basic check
        return {}
    
    def _check_dynamic_analysis(self, file_obj) -> Dict:
        """Perform lightweight dynamic analysis"""
        # This is a simplified version - real dynamic analysis would be more complex
        file_obj.seek(0)
        content = file_obj.read(min(file_obj.size, 64 * 1024))  # Read first 64KB
        file_obj.seek(0)
        
        # Check for dynamic threat indicators
        dynamic_indicators = [
            b'CreateRemoteThread',
            b'VirtualAllocEx',
            b'WriteProcessMemory',
            b'SetWindowsHookEx',
            b'keylogger',
            b'screenshot',
            b'password',
            b'credential',
            b'bitcoin',
            b'cryptocurrency',
            b'ransomware',
        ]
        
        detected_indicators = []
        for indicator in dynamic_indicators:
            if indicator in content:
                detected_indicators.append(indicator.decode('ascii', errors='ignore'))
        
        if detected_indicators:
            return {
                'threat_detected': True,
                'threat_sources': ['dynamic_analysis'],
                'threat_confidence': min(len(detected_indicators) * 20, 90),
                'threat_details': [f'Dynamic indicator: {ind}' for ind in detected_indicators[:3]]
            }
        
        return {}
    
    def _check_community_reports(self, file_hash: str) -> Dict:
        """Check against community threat reports"""
        # Check if this hash has been reported by the community
        community_key = f"community_report:{file_hash}"
        reports = cache.get(community_key, [])
        
        if reports and len(reports) >= 3:  # At least 3 reports
            return {
                'threat_detected': True,
                'threat_sources': ['community_reports'],
                'threat_confidence': min(len(reports) * 15, 85),
                'threat_details': [f'Community reports: {len(reports)} users flagged this file']
            }
        
        return {}
    
    def report_threat(self, file_hash: str, threat_type: str, confidence: int, details: str):
        """Report a new threat to the system"""
        threat_key = f"threat_intel:{file_hash}"
        threat_info = {
            'type': threat_type,
            'confidence': confidence,
            'description': details,
            'reported_at': timezone.now().isoformat()
        }
        cache.set(threat_key, threat_info, self.threat_cache_ttl)
        
        security_logger.warning(f"New threat reported: {file_hash} - {threat_type} - {details}")
    
    def add_community_report(self, file_hash: str, user_id: str, reason: str):
        """Add a community report for a file"""
        community_key = f"community_report:{file_hash}"
        reports = cache.get(community_key, [])
        
        # Avoid duplicate reports from same user
        if not any(report.get('user_id') == user_id for report in reports):
            reports.append({
                'user_id': user_id,
                'reason': reason,
                'timestamp': timezone.now().isoformat()
            })
            cache.set(community_key, reports, 86400 * 7)  # Keep for 7 days


class EnhancedMalwareScanner:
    """
    Enhanced malware scanner with behavioral analysis and real-time threat detection
    Task 1.2.3 Implementation - Complete enhanced malware scanner
    """
    
    # Known malware file hashes (MD5) - sample database
    MALWARE_HASHES = {
        # Example malware hashes (these are fake for demonstration)
        'e3b0c44298fc1c149afbf4c8996fb924': 'Generic.Trojan',
        '5d41402abc4b2a76b9719d911017c592': 'Test.Malware',
        # Add real malware hashes from threat intelligence feeds
    }
    
    # Suspicious file patterns
    SUSPICIOUS_PATTERNS = {
        'executable_headers': [
            b'MZ',  # PE executable
            b'\x7fELF',  # ELF executable
            b'\xfe\xed\xfa\xce',  # Mach-O 32-bit
            b'\xfe\xed\xfa\xcf',  # Mach-O 64-bit
            b'\xca\xfe\xba\xbe',  # Java class file
        ],
        
        'script_patterns': [
            rb'<script[^>]*>.*?</script>',
            rb'javascript:',
            rb'vbscript:',
            rb'data:text/html',
            rb'eval\s*\(',
            rb'exec\s*\(',
            rb'system\s*\(',
            rb'shell_exec\s*\(',
        ],
        
        'php_patterns': [
            rb'<\?php',
            rb'<\?=',
            rb'<\?\s',
            rb'eval\s*\(\s*base64_decode',
            rb'eval\s*\(\s*gzinflate',
            rb'eval\s*\(\s*str_rot13',
        ],
        
        'sql_injection_patterns': [
            rb'UNION\s+SELECT',
            rb'DROP\s+TABLE',
            rb'DELETE\s+FROM',
            rb'INSERT\s+INTO',
            rb'UPDATE\s+.*\s+SET',
            rb'--\s*$',
            rb'/\*.*?\*/',
        ],
        
        'command_injection_patterns': [
            rb';\s*rm\s+-rf',
            rb';\s*cat\s+/etc/passwd',
            rb';\s*wget\s+',
            rb';\s*curl\s+',
            rb'`[^`]*`',
            rb'\$\([^)]*\)',
        ],
        
        'archive_bombs': [
            rb'PK\x03\x04.*PK\x03\x04.*PK\x03\x04',  # Multiple ZIP headers
            rb'BZh[0-9]1AY&SY',  # BZIP2 bomb signature
            rb'\x1f\x8b\x08.*\x1f\x8b\x08',  # Multiple GZIP headers
        ],
        
        'polyglot_files': [
            rb'%PDF-.*<html',  # PDF with HTML
            rb'\xff\xd8\xff.*<script',  # JPEG with script
            rb'\x89PNG.*<\?php',  # PNG with PHP
        ],
    }
    
    # Entropy thresholds for detecting packed/encrypted content
    HIGH_ENTROPY_THRESHOLD = 7.5
    SUSPICIOUS_ENTROPY_THRESHOLD = 6.5
    
    def __init__(self):
        """Initialize the enhanced malware scanner"""
        self.scan_results = {}
        self.behavioral_analyzer = BehavioralAnalyzer()
        self.threat_detector = RealTimeThreatDetector()
    
    def scan_file(self, file_obj, filename: str, client_ip: str = None, user_id: str = None) -> Dict[str, any]:
        """
        Comprehensive malware scan with behavioral analysis and real-time threat detection
        
        Args:
            file_obj: File object to scan
            filename: Original filename
            client_ip: Client IP address for behavioral analysis
            user_id: User ID for behavioral analysis
            
        Returns:
            Dict with scan results
            
        Raises:
            ValidationError: If malware is detected
        """
        scan_result = {
            'filename': filename,
            'file_size': file_obj.size,
            'is_clean': True,
            'threats_detected': [],
            'warnings': [],
            'scan_details': {
                'hash_scan': False,
                'signature_scan': False,
                'heuristic_scan': False,
                'entropy_analysis': False,
                'behavioral_analysis': False,
                'real_time_detection': False,
            },
            'behavioral_analysis': {},
            'real_time_threats': {},
            'risk_score': 0
        }
        
        try:
            # Step 1: Hash-based detection
            self._hash_based_scan(file_obj, scan_result)
            
            # Step 2: Signature-based detection
            self._signature_based_scan(file_obj, scan_result)
            
            # Step 3: Heuristic analysis
            self._heuristic_analysis(file_obj, scan_result)
            
            # Step 4: Entropy analysis
            self._entropy_analysis(file_obj, scan_result)
            
            # Step 5: File structure analysis
            self._structure_analysis(file_obj, scan_result)
            
            # Step 6: Behavioral analysis (if client info available)
            if client_ip:
                behavioral_result = self.behavioral_analyzer.analyze_upload_behavior(
                    file_obj, client_ip, user_id
                )
                scan_result['behavioral_analysis'] = behavioral_result
                scan_result['risk_score'] += behavioral_result.get('risk_score', 0)
                scan_result['scan_details']['behavioral_analysis'] = True
                
                # Add behavioral threats to main threats list
                if behavioral_result.get('behavioral_flags'):
                    for flag in behavioral_result['behavioral_flags']:
                        scan_result['threats_detected'].append(f"Behavioral: {flag}")
            
            # Step 7: Real-time threat detection
            file_hash = scan_result.get('file_hash')
            if file_hash:
                real_time_result = self.threat_detector.check_real_time_threats(file_obj, file_hash)
                scan_result['real_time_threats'] = real_time_result
                scan_result['scan_details']['real_time_detection'] = True
                
                if real_time_result.get('threat_detected'):
                    scan_result['threats_detected'].extend(real_time_result.get('threat_details', []))
            
            # Final assessment
            # Determine if file is clean based on threats and risk score
            high_risk_threshold = 70
            critical_risk_threshold = 90
            
            if scan_result['threats_detected'] or scan_result['risk_score'] >= critical_risk_threshold:
                scan_result['is_clean'] = False
                threat_list = ', '.join(scan_result['threats_detected'][:3])  # Show first 3 threats
                
                # Flag suspicious IP if behavioral issues detected
                if client_ip and scan_result.get('behavioral_analysis', {}).get('behavioral_flags'):
                    self.behavioral_analyzer.flag_suspicious_ip(
                        client_ip, 
                        f"Malicious file upload: {filename}"
                    )
                
                security_logger.error(
                    f"Malware detected in {filename}: {threat_list} (Risk Score: {scan_result['risk_score']})"
                )
                raise ValidationError(
                    f"File contains malicious content: {threat_list}"
                )
            elif scan_result['risk_score'] >= high_risk_threshold:
                scan_result['warnings'].append(f"High risk score: {scan_result['risk_score']}")
                security_logger.warning(
                    f"High-risk file detected: {filename} (Risk Score: {scan_result['risk_score']})"
                )
            
            # Log clean scan
            security_logger.info(f"Malware scan clean: {filename}")
            
            return scan_result
            
        except ValidationError:
            raise
        except Exception as e:
            security_logger.error(f"Malware scan error for {filename}: {str(e)}")
            raise ValidationError(f"Error during malware scan: {str(e)}")
    
    def _hash_based_scan(self, file_obj, result: Dict):
        """Hash-based malware detection"""
        file_obj.seek(0)
        
        # Calculate MD5 hash
        md5_hash = hashlib.md5()
        for chunk in iter(lambda: file_obj.read(4096), b""):
            md5_hash.update(chunk)
        
        file_hash = md5_hash.hexdigest()
        file_obj.seek(0)
        
        # Check against known malware hashes
        if file_hash in self.MALWARE_HASHES:
            malware_name = self.MALWARE_HASHES[file_hash]
            result['threats_detected'].append(f"Known malware: {malware_name}")
        
        result['scan_details']['hash_scan'] = True
        result['file_hash'] = file_hash
    
    def _signature_based_scan(self, file_obj, result: Dict):
        """Signature-based malware detection"""
        file_obj.seek(0)
        
        # Read file content in chunks
        chunk_size = 8192
        content_buffer = b""
        
        while True:
            chunk = file_obj.read(chunk_size)
            if not chunk:
                break
            
            content_buffer += chunk
            
            # Keep buffer size manageable
            if len(content_buffer) > 1024 * 1024:  # 1MB buffer
                self._scan_buffer_for_patterns(content_buffer[:512*1024], result)
                content_buffer = content_buffer[512*1024:]
        
        # Scan remaining buffer
        if content_buffer:
            self._scan_buffer_for_patterns(content_buffer, result)
        
        file_obj.seek(0)
        result['scan_details']['signature_scan'] = True
    
    def _scan_buffer_for_patterns(self, buffer: bytes, result: Dict):
        """Scan buffer for malicious patterns with context awareness"""
        filename = result.get('filename', '').lower()
        
        # Get file extension for context-aware scanning
        file_extension = None
        if '.' in filename:
            file_extension = '.' + filename.split('.')[-1]
        
        # For image files, be more intelligent about executable header detection
        is_image_file = file_extension in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp']
        
        for category, patterns in self.SUSPICIOUS_PATTERNS.items():
            for pattern in patterns:
                if isinstance(pattern, bytes):
                    # Special handling for executable headers in image files
                    if category == 'executable_headers' and is_image_file:
                        # Only flag if the executable header is at the very beginning of the file
                        # This prevents false positives from binary image data containing "MZ" bytes
                        if pattern == b'MZ' and buffer.startswith(pattern):
                            result['threats_detected'].append(f"Suspicious pattern: {category}")
                            break
                        elif pattern != b'MZ' and pattern in buffer:
                            # Other executable headers (ELF, Mach-O) are still checked normally
                            result['threats_detected'].append(f"Suspicious pattern: {category}")
                            break
                    else:
                        # Normal pattern detection for non-image files or non-executable patterns
                        if pattern in buffer:
                            result['threats_detected'].append(f"Suspicious pattern: {category}")
                            break
                else:  # regex pattern
                    if re.search(pattern, buffer, re.IGNORECASE | re.MULTILINE):
                        result['threats_detected'].append(f"Suspicious pattern: {category}")
                        break
    
    def _heuristic_analysis(self, file_obj, result: Dict):
        """Heuristic analysis for unknown threats"""
        file_obj.seek(0)
        content = file_obj.read(min(file_obj.size, 1024 * 1024))  # Read up to 1MB
        file_obj.seek(0)
        
        # Check for suspicious characteristics
        
        # 1. High ratio of non-printable characters
        printable_chars = sum(1 for c in content if 32 <= c <= 126)
        if len(content) > 0:
            printable_ratio = printable_chars / len(content)
            if printable_ratio < 0.1 and len(content) > 1000:
                result['warnings'].append("High ratio of non-printable characters")
        
        # 2. Suspicious string patterns
        suspicious_strings = [
            b'CreateProcess',
            b'VirtualAlloc',
            b'WriteProcessMemory',
            b'SetWindowsHookEx',
            b'RegCreateKey',
            b'RegSetValue',
            b'WinExec',
            b'ShellExecute',
            b'URLDownloadToFile',
            b'InternetOpen',
            b'HttpSendRequest',
        ]
        
        for sus_string in suspicious_strings:
            if sus_string in content:
                result['warnings'].append(f"Suspicious API call: {sus_string.decode('ascii', errors='ignore')}")
        
        # 3. Base64 encoded content (potential obfuscation)
        base64_pattern = rb'[A-Za-z0-9+/]{20,}={0,2}'
        base64_matches = re.findall(base64_pattern, content)
        if len(base64_matches) > 10:
            result['warnings'].append("Multiple base64 encoded strings detected")
        
        # 4. Hex encoded content
        hex_pattern = rb'(?:[0-9a-fA-F]{2}){20,}'
        hex_matches = re.findall(hex_pattern, content)
        if len(hex_matches) > 5:
            result['warnings'].append("Multiple hex encoded strings detected")
        
        result['scan_details']['heuristic_scan'] = True
    
    def _entropy_analysis(self, file_obj, result: Dict):
        """Analyze file entropy to detect packed/encrypted content with context awareness"""
        file_obj.seek(0)
        
        # Get file extension for context-aware entropy analysis
        filename = result.get('filename', '').lower()
        file_extension = None
        if '.' in filename:
            file_extension = '.' + filename.split('.')[-1]
        
        # Different entropy thresholds for different file types
        is_image_file = file_extension in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.webp']
        is_compressed_file = file_extension in ['.zip', '.rar', '.7z', '.gz', '.bz2']
        
        # Adjust thresholds based on file type
        if is_image_file:
            # Images, especially compressed formats like PNG/JPEG, naturally have high entropy
            high_entropy_threshold = 8.2  # Much higher for images
            suspicious_entropy_threshold = 7.8
        elif is_compressed_file:
            # Compressed files naturally have high entropy
            high_entropy_threshold = 8.0
            suspicious_entropy_threshold = 7.5
        else:
            # Use default thresholds for other files
            high_entropy_threshold = self.HIGH_ENTROPY_THRESHOLD  # 7.5
            suspicious_entropy_threshold = self.SUSPICIOUS_ENTROPY_THRESHOLD  # 6.5
        
        # Calculate entropy for different sections of the file
        section_size = min(8192, file_obj.size // 4) if file_obj.size > 8192 else file_obj.size
        entropies = []
        
        for i in range(0, min(file_obj.size, 32768), section_size):
            file_obj.seek(i)
            section = file_obj.read(section_size)
            if section:
                entropy = self._calculate_entropy(section)
                entropies.append(entropy)
        
        if entropies:
            avg_entropy = sum(entropies) / len(entropies)
            max_entropy = max(entropies)
            
            if max_entropy > high_entropy_threshold:
                if is_image_file:
                    # For images, log but don't treat as malicious unless extremely high
                    security_logger.info(f"High entropy detected in image file {filename}: {max_entropy:.2f}")
                    if max_entropy > 8.5:  # Only flag truly extreme entropy
                        result['warnings'].append(f"Unusually high entropy for image: {max_entropy:.2f}")
                else:
                    result['threats_detected'].append(f"Extremely high entropy detected: {max_entropy:.2f}")
            elif avg_entropy > suspicious_entropy_threshold:
                if not is_image_file:  # Don't warn about entropy in images
                    result['warnings'].append(f"Suspicious entropy level: {avg_entropy:.2f}")
        
        file_obj.seek(0)
        result['scan_details']['entropy_analysis'] = True
    
    def _calculate_entropy(self, data: bytes) -> float:
        """Calculate Shannon entropy of data"""
        if not data:
            return 0
        
        # Count byte frequencies
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        # Calculate entropy
        import math
        entropy = 0
        data_len = len(data)
        for count in byte_counts:
            if count > 0:
                probability = count / data_len
                entropy -= probability * math.log2(probability)
        
        return entropy
    
    def _structure_analysis(self, file_obj, result: Dict):
        """Analyze file structure for anomalies"""
        file_obj.seek(0)
        header = file_obj.read(1024)
        file_obj.seek(0)
        
        # Check for polyglot files (files that are valid in multiple formats)
        polyglot_indicators = [
            (b'%PDF-', b'<html'),  # PDF with HTML
            (b'\xff\xd8\xff', b'<script'),  # JPEG with script
            (b'\x89PNG', b'<?php'),  # PNG with PHP
            (b'GIF8', b'<script'),  # GIF with script
        ]
        
        for indicator1, indicator2 in polyglot_indicators:
            if indicator1 in header and indicator2 in header:
                result['threats_detected'].append("Polyglot file detected")
                break
        
        # Check for embedded files
        embedded_signatures = [
            b'%PDF-',  # Embedded PDF
            b'\xff\xd8\xff',  # Embedded JPEG
            b'\x89PNG',  # Embedded PNG
            b'PK\x03\x04',  # Embedded ZIP
        ]
        
        signature_count = 0
        for signature in embedded_signatures:
            if header.count(signature) > 1:
                signature_count += 1
        
        if signature_count > 1:
            result['warnings'].append("Multiple file signatures detected")
    
    def update_malware_database(self, new_hashes: Dict[str, str]):
        """
        Update malware hash database
        
        Args:
            new_hashes: Dict of hash -> malware_name mappings
        """
        self.MALWARE_HASHES.update(new_hashes)
        security_logger.info(f"Updated malware database with {len(new_hashes)} new hashes")
    
    def get_scan_statistics(self) -> Dict[str, int]:
        """Get enhanced scanning statistics"""
        stats = {
            'total_scans': len(self.scan_results),
            'clean_files': sum(1 for r in self.scan_results.values() if r['is_clean']),
            'infected_files': sum(1 for r in self.scan_results.values() if not r['is_clean']),
            'files_with_warnings': sum(1 for r in self.scan_results.values() if r['warnings']),
            'behavioral_flags': sum(
                len(r.get('behavioral_analysis', {}).get('behavioral_flags', []))
                for r in self.scan_results.values()
            ),
            'real_time_threats': sum(
                1 for r in self.scan_results.values() 
                if r.get('real_time_threats', {}).get('threat_detected', False)
            ),
            'high_risk_files': sum(
                1 for r in self.scan_results.values() 
                if r.get('risk_score', 0) >= 70
            )
        }
        return stats
    
    def report_false_positive(self, file_hash: str, user_id: str, reason: str):
        """Report a false positive detection"""
        fp_key = f"false_positive:{file_hash}"
        reports = cache.get(fp_key, [])
        reports.append({
            'user_id': user_id,
            'reason': reason,
            'timestamp': timezone.now().isoformat()
        })
        cache.set(fp_key, reports, 86400 * 30)  # Keep for 30 days
        
        security_logger.info(f"False positive reported: {file_hash} by user {user_id} - {reason}")
    
    def get_threat_intelligence_summary(self) -> Dict[str, any]:
        """Get summary of current threat intelligence"""
        return {
            'active_threats': len(self.threat_detector.active_threats),
            'threat_feeds': len(self.threat_detector.threat_feeds),
            'cache_ttl': self.threat_detector.threat_cache_ttl,
            'last_updated': timezone.now().isoformat()
        }


# Global enhanced scanner instance
malware_scanner = EnhancedMalwareScanner()


def scan_file_for_malware(file_obj, filename: str = None, client_ip: str = None, user_id: str = None) -> Dict[str, any]:
    """
    Enhanced malware scan with behavioral analysis and real-time threat detection
    
    Args:
        file_obj: File object to scan
        filename: Optional filename
        client_ip: Client IP address for behavioral analysis
        user_id: User ID for behavioral analysis
        
    Returns:
        Enhanced scan results dictionary
        
    Raises:
        ValidationError: If malware is detected
    """
    if not filename:
        filename = getattr(file_obj, 'name', 'unknown')
    
    return malware_scanner.scan_file(file_obj, filename, client_ip, user_id)


def report_threat_to_community(file_hash: str, user_id: str, reason: str):
    """
    Report a threat to the community threat database
    
    Args:
        file_hash: Hash of the malicious file
        user_id: User reporting the threat
        reason: Reason for reporting
    """
    malware_scanner.threat_detector.add_community_report(file_hash, user_id, reason)


def get_malware_scan_stats() -> Dict[str, any]:
    """
    Get comprehensive malware scanning statistics
    
    Returns:
        Dictionary with scanning statistics
    """
    return malware_scanner.get_scan_statistics()